{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie_Recommendation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tjH81J2-85D"
      },
      "source": [
        "Summary\n",
        "===============\n",
        "Our project is to give the users recommendations based on the similar users. We used collaborative filtering, Matrix Factorization technique to achieve this.\n",
        "\n",
        "Dataset\n",
        "============\n",
        "We used dataset of movie ratings provided by movielens, which contains movie id, user id, ratings and timestamp.\n",
        "\n",
        "**Name** : ml-latest-small \n",
        "\n",
        "\n",
        "**Link** : https://grouplens.org/datasets/movielens/\n",
        "\n",
        "Technique Used\n",
        "==================\n",
        "we used matrix factorization technique by svd.\n",
        "\n",
        "Observations\n",
        "==================\n",
        "We achieved root mean square error of 1.0018 when we take latent features(k) as 5 for svd. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TefyQCtHWurf",
        "outputId": "78c97e95-c3bd-4e2c-d859-a5a247534f55"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "data = pd.read_csv('ratings.csv')\n",
        "movies = pd.read_csv('movies.csv')\n",
        "movieDict = {}\n",
        "\n",
        "#preparing movie dictionary to recommend the titles to users at last.\n",
        "for _,row in movies.iterrows():\n",
        "    movieDict[str(row['movieId'])] = row['title']\n",
        "\n",
        "data['userId'] = data['userId'].astype('str')\n",
        "data['movieId'] = data['movieId'].astype('str')\n",
        "\n",
        "users = data['userId'].unique() #list of all users\n",
        "movies = data['movieId'].unique() #list of all movies\n",
        "\n",
        "print(data.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  userId movieId  rating  timestamp\n",
            "0      1       1     4.0  964982703\n",
            "1      1       3     4.0  964981247\n",
            "2      1       6     4.0  964982224\n",
            "3      1      47     5.0  964983815\n",
            "4      1      50     5.0  964982931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDn2v_oteOAP"
      },
      "source": [
        "Dividing train and test data by 80:20 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSLEqAxcYYGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cdae98b-08b2-4777-fb8d-b35bd5a53078"
      },
      "source": [
        "test = pd.DataFrame(columns=data.columns)\n",
        "train = pd.DataFrame(columns=data.columns)\n",
        "temp = pd.DataFrame(columns=data.columns)\n",
        "test_ratio = 0.2 #fraction of data to be used as test set.\n",
        "\n",
        "for u in users:\n",
        "    temp = data[data['userId'] == u]\n",
        "    n = len(temp)\n",
        "    test_size = int(test_ratio*n)\n",
        "\n",
        "    temp = temp.sort_values('timestamp').reset_index()\n",
        "    temp.drop('index', axis=1, inplace=True)\n",
        "    \n",
        "    dummy_test = temp.iloc[n-1-test_size :]\n",
        "    dummy_train = temp.iloc[: n-2-test_size]\n",
        "    \n",
        "    test = pd.concat([test, dummy_test])\n",
        "    train = pd.concat([train, dummy_train])\n",
        "\n",
        "print(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     userId movieId  rating   timestamp\n",
            "0         1    1210     5.0   964980499\n",
            "1         1     804     4.0   964980499\n",
            "2         1    2018     5.0   964980523\n",
            "3         1    2628     4.0   964980523\n",
            "4         1    2826     4.0   964980523\n",
            "...     ...     ...     ...         ...\n",
            "1035    610   60471     3.5  1493848660\n",
            "1036    610   27778     3.0  1493848667\n",
            "1037    610   55067     3.5  1493848671\n",
            "1038    610  103219     3.5  1493848674\n",
            "1039    610   51666     2.0  1493848680\n",
            "\n",
            "[79676 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zOcCexAeJIh"
      },
      "source": [
        "Converting the ratings data into matrix format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81JXiu9Dmwgt"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.linalg import sqrtm\n",
        "def create_utility_matrix(data, formatizer = {'user':0, 'item': 1, 'value': 2}):\n",
        "    \"\"\"\n",
        "        :param data:      Array-like, 2D, nx3\n",
        "        :param formatizer:pass the formatizer\n",
        "        :return:          utility matrix (n x m), n=users, m=items\n",
        "    \"\"\"\n",
        "        \n",
        "    itemField = formatizer['item']\n",
        "    userField = formatizer['user']\n",
        "    valueField = formatizer['value']\n",
        "    userList = data.iloc[:,userField].tolist()\n",
        "    itemList = data.iloc[:,itemField].tolist()\n",
        "    valueList = data.iloc[:,valueField].tolist()\n",
        "    users = list(set(data.iloc[:,userField]))\n",
        "    items = list(set(data.iloc[:,itemField]))\n",
        "    users_index = {users[i]: i for i in range(len(users))}\n",
        "    pd_dict = {item: [np.nan for i in range(len(users))] for item in items}\n",
        "    for i in range(0,len(data)):\n",
        "        item = itemList[i]\n",
        "        user = userList[i]\n",
        "        value = valueList[i]\n",
        "        pd_dict[item][users_index[user]] = value\n",
        "    X = pd.DataFrame(pd_dict)\n",
        "    X.index = users\n",
        "        \n",
        "    itemcols = list(X.columns)\n",
        "    items_index = {itemcols[i]: i for i in range(len(itemcols))}\n",
        "    # users_index gives us a mapping of user_id to index of user\n",
        "    # items_index provides the same for items\n",
        "    return X, users_index, items_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSgS84NOeDcl"
      },
      "source": [
        "Here we get predicted matrix by using svd model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGhiKcSRnE79"
      },
      "source": [
        "def svd(train, k):\n",
        "    utilMat = np.array(train)\n",
        "    \n",
        "    # the nan or unavailable entries are masked\n",
        "    mask = np.isnan(utilMat)\n",
        "    masked_arr = np.ma.masked_array(utilMat, mask)\n",
        "    item_means = np.mean(masked_arr, axis=0)\n",
        "\n",
        "    # nan entries will replaced by the average rating for each item\n",
        "    utilMat = masked_arr.filled(item_means)\n",
        "    x = np.tile(item_means, (utilMat.shape[0],1))\n",
        "\n",
        "    # we remove the per item average from all entries.\n",
        "    # the above mentioned nan entries will be essentially zero now\n",
        "    utilMat = utilMat - x\n",
        "    # U and V are user and item features\n",
        "    U, s, V=np.linalg.svd(utilMat, full_matrices=False)\n",
        "    s=np.diag(s)\n",
        "    # K latent features\n",
        "    s=s[0:k,0:k]\n",
        "    U=U[:,0:k]\n",
        "    V=V[0:k,:]\n",
        "    s_root=sqrtm(s)\n",
        "    Usk=np.dot(U,s_root)\n",
        "    skV=np.dot(s_root,V)\n",
        "    UsV = np.dot(Usk, skV)\n",
        "    UsV = UsV + x\n",
        "    print(\"svd done\")\n",
        "    return UsV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vePCKHHWd9jD"
      },
      "source": [
        "Calculating root mean square error for our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaY50G0BnIU0",
        "outputId": "78893504-6095-460b-b73a-0aa10940c4cc"
      },
      "source": [
        "import math\n",
        "import numpy.ma as ma\n",
        "\n",
        "def rmse(true, pred):\n",
        "    # this will be used towards the end\n",
        "    x = true - pred\n",
        "    return math.sqrt(sum([xi*xi for xi in x])/len(x))\n",
        "\n",
        "# to test the performance over a different number of features\n",
        "no_of_features = [3,5,8,10,15,20,50,75,100]\n",
        "utilMat, users_index, items_index = create_utility_matrix(train)\n",
        "user_pred = {}\n",
        "\n",
        "for f in no_of_features: \n",
        "    svdout = svd(utilMat, k=f)\n",
        "    pred = [] #to store the predicted ratings\n",
        "    user_pred.clear()\n",
        "    for _,row in test.iterrows():\n",
        "        user = row['userId']\n",
        "        item = row['movieId']\n",
        "        u_index = users_index[user]\n",
        "        if item in items_index:\n",
        "            i_index = items_index[item]\n",
        "            pred_rating = svdout[u_index, i_index]\n",
        "        else:\n",
        "            pred_rating = np.mean(svdout[u_index, :])\n",
        "            user_pred.setdefault(user,[]).append([pred_rating,item])\n",
        "        pred.append(pred_rating)\n",
        "    print(rmse(test['rating'], pred))\n",
        "\n",
        "item_dict = dict((v,k) for k,v in items_index.items())\n",
        "#updating user predictions of all movies in a list with predicted ratings\n",
        "for user in users_index.keys():\n",
        "    u_index = users_index[user]\n",
        "    u_ratings = ma.getdata(svdout[u_index, :])\n",
        "    for i in range(len(u_ratings)):\n",
        "        user_pred.setdefault(user, []).append([u_ratings[i],item_dict[i]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svd done\n",
            "1.0025296483722526\n",
            "svd done\n",
            "1.0018187399945997\n",
            "svd done\n",
            "1.0021567262012732\n",
            "svd done\n",
            "1.0020101514806032\n",
            "svd done\n",
            "1.0030428726643206\n",
            "svd done\n",
            "1.0030900965801048\n",
            "svd done\n",
            "1.0061892173848752\n",
            "svd done\n",
            "1.008353047973624\n",
            "svd done\n",
            "1.0102065998882652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E41TeLQAdxPI"
      },
      "source": [
        "List of movies recommended for particular user based on predicted ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgLkPigRqrwS",
        "outputId": "2d42a57a-402c-468e-92b2-94be80fed00c"
      },
      "source": [
        "def recommender(user):\n",
        "    counter = 0\n",
        "\n",
        "    #sorting movies of user based on ratings\n",
        "    if user in user_pred:\n",
        "        user_pred[user].sort(key = lambda x: x[0],reverse=True)\n",
        "\n",
        "    print(\"Recommendations for user : \", user)\n",
        "    #displaying top 100 predicted ratings of a particular user\n",
        "    for pred,item in user_pred[user]:\n",
        "        print(item, movieDict[item])\n",
        "        counter = counter+1\n",
        "        if counter>100:\n",
        "            break\n",
        "\n",
        "recommender('2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for user :  2\n",
            "172705 Tickling Giants (2017)\n",
            "6021 American Friend, The (Amerikanische Freund, Der) (1977)\n",
            "158398 World of Glory (1991)\n",
            "1310 Hype! (1996)\n",
            "40412 Dead Man's Shoes (2004)\n",
            "107771 Only Lovers Left Alive (2013)\n",
            "5745 Four Seasons, The (1981)\n",
            "6983 Jane Eyre (1944)\n",
            "3214 American Flyers (1985)\n",
            "50804 Hannibal Rising (2007)\n",
            "131130 Tom and Jerry: A Nutcracker Tale (2007)\n",
            "27320 Nine Lives of Tomas Katz, The (2000)\n",
            "174053 Black Mirror: White Christmas (2014)\n",
            "6442 Belle époque (1992)\n",
            "496 What Happened Was... (1994)\n",
            "3795 Five Senses, The (1999)\n",
            "3678 Man with the Golden Arm, The (1955)\n",
            "121781 Stuart Little 3: Call of the Wild (2005)\n",
            "124404 Snowflake, the White Gorilla (2011)\n",
            "26350 Passenger, The (Professione: reporter) (1975)\n",
            "48698 Deliver Us from Evil (2006)\n",
            "7122 King of Hearts (1966)\n",
            "132153 Buzzard (2015)\n",
            "86721 Idiots and Angels (2008)\n",
            "136556 Kung Fu Panda: Secrets of the Masters (2011)\n",
            "112512 Colourful (Karafuru) (2010)\n",
            "6945 My Architect: A Son's Journey (2003)\n",
            "3851 I'm the One That I Want (2000)\n",
            "6818 Come and See (Idi i smotri) (1985)\n",
            "84273 Zeitgeist: Moving Forward (2011)\n",
            "64501 Che: Part Two (2008)\n",
            "147410 A Perfect Day (2015)\n",
            "158027 SORI: Voice from the Heart (2016)\n",
            "26169 Branded to Kill (Koroshi no rakuin) (1967)\n",
            "118894 Scooby-Doo! Abracadabra-Doo (2010)\n",
            "96832 Holy Motors (2012)\n",
            "8327 Dolls (2002)\n",
            "78836 Enter the Void (2009)\n",
            "1631 Assignment, The (1997)\n",
            "25906 Mr. Skeffington (1944)\n",
            "6201 Lady Jane (1986)\n",
            "283 New Jersey Drive (1995)\n",
            "5059 Little Dieter Needs to Fly (1997)\n",
            "6408 Animals are Beautiful People (1974)\n",
            "86237 Connections (1978)\n",
            "102084 Justice League: Doom (2012) \n",
            "91386 Happy Feet Two (2011)\n",
            "876 Supercop 2 (Project S) (Chao ji ji hua) (1993)\n",
            "69469 Garfield's Pet Force (2009)\n",
            "5244 Shogun Assassin (1980)\n",
            "136355 Big Top Scooby-Doo! (2012)\n",
            "8238 Little Murders (1971)\n",
            "7815 True Stories (1986)\n",
            "70451 Max Manus (2008)\n",
            "120130 Into the Forest of Fireflies' Light (2011)\n",
            "126088 A Flintstones Christmas Carol (1994)\n",
            "4135 Monster Squad, The (1987)\n",
            "5241 Seems Like Old Times (1980)\n",
            "6611 Umberto D. (1952)\n",
            "139640 Ooops! Noah is Gone... (2015)\n",
            "55444 Control (2007)\n",
            "6086 I, the Jury (1982)\n",
            "108795 Wonder Woman (2009)\n",
            "79897 Get Low (2009)\n",
            "138632 Tokyo Tribe (2014)\n",
            "2323 Cruise, The (1998)\n",
            "141718 Deathgasm (2015)\n",
            "26612 Better Tomorrow II, A (Ying hung boon sik II) (1987)\n",
            "47404 Mind Game (2004)\n",
            "109633 Garden of Words, The (Koto no ha no niwa) (2013)\n",
            "77846 12 Angry Men (1997)\n",
            "8580 Into the Woods (1991)\n",
            "1759 Four Days in September (O Que É Isso, Companheiro?) (1997)\n",
            "6192 Open Hearts (Elsker dig for evigt) (2002)\n",
            "162344 Tom Segura: Mostly Stories (2016)\n",
            "124851 Delirium (2014)\n",
            "1349 Vampire in Venice (Nosferatu a Venezia) (Nosferatu in Venice) (1986)\n",
            "2512 Ballad of Narayama, The (Narayama bushiko) (1983)\n",
            "4813 When Worlds Collide (1951)\n",
            "30745 Gozu (Gokudô kyôfu dai-gekijô: Gozu) (2003)\n",
            "27751 'Salem's Lot (2004)\n",
            "74226 Dream of Light (a.k.a. Quince Tree Sun, The) (Sol del membrillo, El) (1992)\n",
            "114265 Laggies (2014)\n",
            "156025 Ice Age: The Great Egg-Scapade (2016)\n",
            "71268 Tyler Perry's I Can Do Bad All by Myself (2009)\n",
            "64197 Hunger (2008)\n",
            "103602 Craig Ferguson: I'm Here To Help (2013)\n",
            "88448 Paper Birds (Pájaros de papel) (2010)\n",
            "150554 The Love Bug (1997)\n",
            "467 Live Nude Girls (1995)\n",
            "5746 Galaxy of Terror (Quest) (1981)\n",
            "4180 Reform School Girls (1986)\n",
            "141928 Bloodsucking Bastards (2015)\n",
            "72142 Love Exposure (Ai No Mukidashi) (2008)\n",
            "3073 Sandpiper, The (1965)\n",
            "128914 Tom Segura: Completely Normal (2014)\n",
            "2511 Long Goodbye, The (1973)\n",
            "5088 Going Places (Valseuses, Les) (1974)\n",
            "27373 61* (2001)\n",
            "134847 Ghost Graduation (2012)\n",
            "122092 Guy X (2005)\n"
          ]
        }
      ]
    }
  ]
}